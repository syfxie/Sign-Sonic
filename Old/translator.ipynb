{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c339cc5",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22dfb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b538a45",
   "metadata": {},
   "source": [
    "# 3. Detect and Render Keypoints using MMPose Inference Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2868920",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m cam \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 0 is the device value (webcam), can be substituted for the name of a video file\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Access MediaPipe model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmp_holistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m holistic:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cam\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# Read feed\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         ret, frame \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic Model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "# Detect keypoints using holistic model\n",
    "def detect_keypoints(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)    # Convert image from bgr (default channel from opencv feed) to rbg (media pipe detects in rgb)\n",
    "    image.flags.writable = False                    # Set image to unwritable to save memory\n",
    "    results = model.process(image)                  # Detecting keypoints\n",
    "    image.flags.writable = True                     # Set back to writable\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)    # Convert back to bgr\n",
    "    return image, results\n",
    "\n",
    "# Render landmarks on frame in place\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(80, 256, 120), thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.post_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(200, 0, 18), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(100, 0, 18), thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(180, 140, 180), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(200, 180, 180), thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(180, 140, 180), thickness=1, circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(200, 180, 180), thickness=1, circle_radius=1),\n",
    "                             )\n",
    "    \n",
    "\n",
    "# Set up webcam for video capture\n",
    "cam = cv.VideoCapture(0) # 0 is the device value (webcam), can be substituted for the name of a video file\n",
    "\n",
    "# Access MediaPipe model\n",
    "with mp_holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cam.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        # Make detections (result contains all the different landmarks)\n",
    "        image, results = detect_keypoints(frame, holistic)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_landmarks(image, results)\n",
    "\n",
    "        # Show frame to screen (name of window, frame)\n",
    "        cv.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Wait 10 ms for a keypress after the window is shown, if the key returned is q, break\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release webcam\n",
    "    cam.release()\n",
    "\n",
    "    # Close window\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "print('ehllo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d3a25-bafe-493c-9308-cd3390bdaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap_front = cv2.VideoCapture(0) #front\n",
    "cap_back = cv2.VideoCapture(1) #back\n",
    "active_capture = cap_front\n",
    "while True:\n",
    "    ret, frame = active_capture.read()\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"b\"):\n",
    "        active_capture = cap_back\n",
    "    elif key == ord(\"f\"):\n",
    "        active_capture = cap_front\n",
    "        cv2.imshow(\" \",frame)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "print('done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eeceb3-86fb-44c2-b054-0d3798f89ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5d5ac",
   "metadata": {},
   "source": [
    "# 4. Extract Keypoint Data\n",
    "- Concat all landmarks into a numpy array\n",
    "- array of zeros if no landmarks are detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa2fb8-6d7a-4157-b4bc-a64d653d45fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba63f0a-98ba-4e75-bb55-b4da4eaa1d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff47e9-a04b-44cc-bfee-eba432bdc88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94bd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.post_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all landmark coordinates as a single flattened np array\n",
    "# Handle errors when hands are not in the frame: replace landmarks with blank array\n",
    "\n",
    "def extract_landmarks_arrays(results):\n",
    "    if results.pose_landmarks:\n",
    "        pose_array = np.array([[pos.x, pos.y, pos.z, pos.visibility] for pos in results.pose_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        pose_array = np.zeros(33 * 4)\n",
    "\n",
    "    if results.face_landmarks:\n",
    "        face_array = np.array([[pos.x, pos.y, pos.z] for pos in results.face_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        face_array = np.zeros(468 * 3)\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        lh_array = np.array([[pos.x, pos.y, pos.z] for pos in results.left_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        lh_array = np.zeros(21 * 3)\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        rh_array = np.array([[pos.x, pos.y, pos.z] for pos in results.right_hand_landmarks.landmark]).flatten()\n",
    "    else:\n",
    "        rh_array = np.zeros(21 * 3)\n",
    "    \n",
    "    return np.concatenate(pose_array, face_array, lh_array, rh_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0510bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[5, 6, 7], [8, 9, 0]])\n",
    "arr\n",
    "arr.flatten()\n",
    "np.zeros(21 * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f000d9",
   "metadata": {},
   "source": [
    "# 2. Set Up Webcam\n",
    "- setup video capture and loop through frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9495111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up webcam for video capture\n",
    "cam = cv.VideoCapture(0) # 0 is the device value (webcam), can be substituted for the name of a video file\n",
    "\n",
    "while cam.isOpened():\n",
    "\n",
    "    # Read feed\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # Show frame to screen (name of window, frame)\n",
    "    cv.imshow('OpenCV Feed', frame)\n",
    "\n",
    "    # Wait 10 ms for a keypress after the window is shown, if the key returned is q, break\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release webcam\n",
    "cam.release()\n",
    "\n",
    "# Close window\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718f4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a0844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a6ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7665b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f83cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb038141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5110d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ba222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb8033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f9a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce94308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed57a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe046587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c267c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13796619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764e82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
